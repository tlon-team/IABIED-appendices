# Глава 1: Особая сила человечества

Это онлайн-дополнение к Главе 1 книги [«Если кто-то его сделает, все умрут»](https://www.amazon.com/gp/product/0316595640). Ниже мы рассмотрим частые вопросы и раскроем темы из книги.

Некоторые темы не рассматриваются ниже, поскольку они уже освещены в Главе 1 книги. Среди них:

- Что такое «интеллект»?
- Могут ли машины стать умнее людей?
- Существует ли практический предел уровня интеллекта?

## Часто задаваемые вопросы

### Интеллект -- осмысленное понятие?

#### Да. Это слово описывает реальное явление, пусть его и трудно точно определить.

За последние тридцать лет люди получили семьдесят семь Нобелевских премий по химии, а шимпанзе -- ни одной. Инопланетянин, впервые услышав об этом, мог бы заподозрить Нобелевский комитет в предвзятости. Но нет, в людях действительно есть _нечто_, что отличает нас от шимпанзе.

Мысль до банальности проста, но иногда такие вещи важны. Именно наши способности позволили нам высадиться на Луне и вручили судьбу планеты в руки людей, а не шимпанзе. Философы и учёные могут спорить об истинной природе интеллекта, но к какому бы выводу они ни пришли, само явление никуда не денется. Нечто в человеке позволило нам достичь невиданных в природе высот. Это нечто связано с нашим мозгом -- с тем, как мы познаём мир и влияем на него.

#### Если вы не можете дать чему-то точное определение, это не значит, что оно не может вам навредить.

Если вы оказались в лесном пожаре, неважно, понимаете ли вы химию огня. Вы всё равно сгорите.

То же самое и с интеллектом. Если машины начнут превращать поверхность Земли в свою инфраструктуру, выделяя столько тепла, что океаны закипят, будет уже неважно, есть ли у нас точное определение «интеллекта». Мы всё равно погибнем.

Мы имеем в виду именно то, что говорим. В следующих главах мы объясним, почему ожидаем от сверхразумного ИИ таких крайних последствий. В Главе 3 мы покажем, что суперинтеллект будет преследовать свои цели. В Главе 4 -- что эти цели не будут совпадать с тем, чего хотел или о чём просил любой человек. В Главе 5 -- что для достижения своих устремлений ему будет выгоднее забрать ресурсы, нужные нам для выживания. А в Главе 6 -- что он сможет развить собственную инфраструктуру и быстро сделать мир непригодным для жизни.

Чтобы создать интеллект, не нужно иметь его точное определение.
Люди научились добывать огонь до того, как поняли химию горения. Точно так же люди уже близки к созданию разумных машин, несмотря на недостаток понимания -- как мы расскажем в Главе 2.

Не думайте об интеллекте как о математическом понятии, требующем точного определения. Лучше считать «интеллект» названием для наблюдаемого, но пока плохо нами понятого природного явления.

Что-то в человеческом мозге позволяет нам совершать поразительное множество вещей. Мы строим ускорители частиц, разрабатываем новые лекарства, изобретаем сельское хозяйство, пишем романы, проводим военные кампании. Нечто в наших умах позволяет нам делать всё это, а вот мыши и шимпанзе не могут ничего из перечисленного. Хоть у нас пока и нет полного научного понимания этого ментального различия, полезно дать ему имя.

Полезно и иметь возможность говорить об интеллекте, превосходящем наш собственный. Уже сегодня ИИ превосходят человека в разных узких областях. Например, современные шахматные программы сверхчеловечны в игре в шахматы. Естественно задаться вопросом, что произойдёт, когда мы создадим ИИ, превосходящие людей в научных открытиях, технологических разработках, социальных манипуляциях или стратегическом планировании. И так же логично спросить, что случится, когда появятся машины, которые будут лучше людей во всём.

Когда и если появится ИИ, способный проводить научные исследования мирового уровня в тысячи раз быстрее лучших учёных, мы сможем заявить, что он «не по-настоящему разумен», возможно, потому, что он приходит к выводам совсем не так, как человек. Это может быть даже правдой, в зависимости от выбранного определения «интеллекта». Но реальное влияние такого ИИ будет огромным, как бы мы его ни называли.

Нам нужна какая-то терминология, чтобы говорить о подобном влиянии и о машинах, радикально превосходящих нас в прогнозировании мира и управлении им. В этой книге мы выбираем простой путь и присваиваем ярлык «интеллект» именно способностям, а не конкретным внутренним процессам, что их порождают.

### Имеет ли смысл понятие «человеческий уровень интеллекта»?

#### Во многих случаях, да.

Люди создали развитую технологическую цивилизацию, а шимпанзе -- нет. Похоже, шимпанзе в каком-то смысле нам не ровня, хотя они общаются, используют инструменты и обладают многими впечатляющими навыками. Поэтому полезно говорить о «человеческом уровне», даже если использовать интеллект людей как мерило бывает проблематично.

Представьте, что однажды в глубинах космоса мы встретили инопланетную цивилизацию, примерно на нашем технологическом уровне. Эти существа могут ходить хуже людей, но плавать лучше. Они могут превосходить нас в состязательных играх вроде шахмат или покера, но уступать в абстрактной математике. Или наоборот. Их мышление может быть медленнее, но память -- лучше, или наоборот.

Как определить, интеллект этих пришельцев -- «человеческого уровня»? (И почему бы не спросить, достигает ли наш интеллект «инопланетного»?)

Говоря об «интеллекте человеческого уровня», мы имеем в виду свойство, благодаря которому люди способны создать и поддерживать технологическую цивилизацию, на что не способны шимпанзе.

С исторической (а точнее, с антропологической) точки зрения, похоже, в какой-то момент после расхождения путей людей и шимпанзе был преодолён некий порог. Дело не в том, что у людей -- лучшие учёные, а у шимпанзе -- посредственные, чьи статьи не воспроизводятся. Обезьяны не то что плохих научных статей не публикуют -- они вообще писать не умеют! Мозг человека и шимпанзе биологически очень схож. Но мы перешли некую черту. За ней мы смогли создать цивилизацию, плавить железо, запускать ракеты в космос, читать и писать.

На первый взгляд, если отбросить все теории, кажется, будто прорвало некую плотину, и за ней хлынул огромный поток интеллекта. По какой-то неведомой причине, «началось».

Конечно, найдутся те, кто остроумно возразит этой идее. Но они будут придираться к словам и определениям, а не заявлять: «Я обнаружил свидетельства, что Homo erectus пытались строить ядерные реакторы два миллиона лет назад, просто у них это очень плохо получалось».

Похоже, достаточно мощный и универсальный интеллект для создания цивилизации появился в мире стремительно, чётко отделив Homo sapiens от остальных животных. Мы не держимся за ярлык «интеллект человеческого уровня», у него много недостатков. Но как это ни назови, полезно иметь понятие для тех, кто уже перешёл тот самый порог, в чём бы он ни заключался.

### Разве интеллект не состоит из множества навыков?

#### Да, но они сильно пересекаются.

Допустим, я лучше моей сестры сочиняю классическую музыку, а она лучше меня пишет романы. Невозможно однозначно сказать, кто из нас «умнее», ведь это просто разные навыки. Так почему же осмысленнее говорить об ИИ «умнее» человека?

Наш ответ: если я лучше в чём-то одном, а сестра -- в чём-то другом, однозначно сравнить нас затруднительно. Но если я преуспеваю в одном деле, а сестра -- в двух тысячах, то уже как-то глупо настаивать, что мы на равных. Или утверждать, что о нашем положении вообще ничего нельзя сказать.

«Если кто-то его сделает, все умрут» -- книга о вероятных практических последствиях будущего прогресса ИИ. Для осмысленного разговора об этих последствиях не нужно уметь сравнивать ChatGPT, людей и плодовых мушек и точно определять «уровень интеллекта» каждой из этих трёх систем. Достаточно видеть, что ИИ осваивают всё более широкий круг навыков и со временем превзойдут людей в тех, что имеют огромное практическое значение.

### А интеллект не переоценён?

#### Только если вы используете слишком узкое определение «интеллекта».

Иногда мы сталкиваемся с такими утверждениями: «Интеллект -- не всё, что нужно для успеха! Многие из самых успешных людей --  харизматичные политики, руководители компаний или поп-звёзды! Умники в чём-то лучше, но миром правят не они».

Мы не оспариваем это утверждение. Скорее, «интеллектом» (в этой книге) мы называем то, что отличает не умников от качков, а людей от мышей.

В голливудском сценарии «умным» обычно называют персонажа с книжными знаниями. Может, он знаток истории или гениальный изобретатель. Может, он хорошо играет в шахматы или раскрывает преступления.

У голливудского «ботаника» есть свои сильные стороны, но они уравновешиваются стереотипными слабостями. Возможно, ему не хватает эмоционального интеллекта, здравого смысла или житейской хитрости. Может быть, ему недостаёт ловкости рук или харизмы.

Но харизма -- не вещество из какой-то железы. Харизма, как и «книжные знания», -- результат процессов в мозге. В том числе и _неосознанных_: поведение, делающее кого-то харизматичным, не всегда находится под его сознательным контролем. В конечном счёте, и харизма, и инженерный талант -- часть неврологической разнецы между человеком и мышью. Не так важно, как эти две способности распределены между умниками и поп-звёздами.

«Искусственным интеллектом» мы называем не «искусственные книжные знания», а «искусственное всё-что-отделяет-человеческий-мозг-от-мышиного». Силу, что позволяет людям летать на Луну, оратору -- доводить толпу до слёз, а солдату -- метко целиться из винтовки. Всё сразу.

### «Обобщённый интеллект» -- осмысленное понятие?

#### Да.

Сапсан может пикировать со скоростью 380 километров в час. Кашалот может нырять на мили вглубь океана. Сапсан утонул бы в море, а кит бы плюхнулся обратно, попробуй он взлететь. Но люди как-то сделали себе металлические оболочки и смогли и полететь быстрее сапсана, и нырнуть глубже кита.

В эволюционном окружении наших предков не было ни глубокого океана, ни отбора по умению парить в небе. Мы справились с этими и многими другими задачами не благодаря особым инстинктам, а исключительно за счёт универсальности нашего разума.

Каким-то образом наши предки прошли отбор на умение в самом общем смысле _хорошо решать задачи_, хоть они и редко сталкивались с инженерной задачей сложнее, чем сделать копьё.

Это умение у людей _идеально_? Очевидно, нет. Люди, кажется, неспособны научиться играть в шахматы на уровне лучших шахматных ИИ, по крайней мере, с ограниченным временем на партию. Сверхчеловеческий уровень игры в шахматы очевидно возможен, но людям без посторонней помощи не доступен. Наш интеллект не универсален -- то есть мы не можем научиться делать _всё_ физически возможное.[^13] Эта «универсальность» людей не означает способности делать что угодно одним лишь мозгом. Но всё же человеческие способности учиться и решать новые задачи несравненно более общие, чем у узкоспециализированного шахматного ИИ вроде [Deep Blue](https://www.ibm.com/history/deep-blue).

Но эта обобщённость -- не всё или ничего. У неё есть разные уровни.

Deep Blue был не очень универсален -- он не мог управлять ничем, кроме шахматной доски. Он был способен находить выигрышные ходы, но не съездить в магазина за молоком, или тем более открыть законы гравитации и спроектировать лунную ракету. Deep Blue не умел играть даже в другие настольные игры, будь то простые шашки или более сложная игра го.

Для контраста возьмём [AlphaGo](https://deepmind.google/research/projects/alphago/) -- ИИ, который наконец одолел го. Лежащие в его основе алгоритмы способны отлично играть и в шахматы. Го не поддалось первому же найденному человечеством шахматному алгоритму. Но вариант первого же алгоритма для го смог побить рекорды в шахматах, а заодно преуспел в видеоиграх на Atari. Пока что новые алгоритмы не умеют ходить в магазин за молоком, но они уже _более_ общие.

Оказывается, одни виды интеллекта гораздо обобщённее других.

### Но «обобщённость» точно определить ещё сложнее, чем «интеллект».

#### Легко сказать, что люди обобщённее плодовых мушек. Но как это работает?

Мы не знаем. Пока не существует зрелой формальной теории «обобщённости». Мы можем лишь рассуждать на пальцах: интеллект «более обобщён», если он способен предсказывать события и управлять ими в более широком диапазоне окружений, несмотря на большее разнообразие и сложных задач. Но у нас нет формализованной количественной меры этих окружений и задач, чтобы определение стало точным.

Звучит неубедительно? Мы тоже не в восторге. Мы очень надеемся, что человечество успеет лучше в этом разобраться, прежде чем пытаться создавать обобщённо разумные машины. Это помогло бы плачевной технической ситуации, которую мы опишем в главах 10 и 11.

Хотя у нас нет формального описания этого явления, наблюдения за окружающим миром всё же позволяют нам вывести кое-что про обобщённость.

Мы знаем, что люди не рождаются с врождёнными знаниями и навыками для постройки небоскрёбов и лунных ракет. Наши далёкие предки никогда не имели с ними дел, так что эти знания не могли закодироваться в наших генах. Всё это -- результаты способности обучаться тому, чего мы не понимали от рождения.

Чтобы оценить обобщённость, надо смотреть не на то, сколько что-то _знает_, а сколько оно _учится_.

В некотором смысле люди обучаются лучше мышей. Не то чтобы мыши совсем этого не умели -- например, они могут научиться проходить лабиринт. Но люди способны усваивать более сложные и странные вещи и эффективнее связывать фрагменты знаний воедино.

Как именно это работает? Что есть у нас, чего нет у мышей?

Представьте себе двух человек, которые после переезда учатся ориентироваться в новом городе.

Алиса запоминает нужные ей маршруты. Чтобы добраться от дома до хозяйственного магазина, она поворачивает налево на третьей улице, налево на втором светофоре, затем проезжает ещё два квартала и поворачивает направо на парковку. Отдельно она запоминает дорогу до продуктового и до офиса.

Бетти же изучает и усваивает карту города.

Алиса может хорошо справляться с повседневными поездками, но если ей придётся ехать в новое место без навигатора, у неё будут проблемы. Бет, напротив, тратит больше времени на планирование маршрутов, но у неё гораздо больше возможностей.

Алиса, возможно, быстрее на заученных маршрутах, но Бетти лучше справится с поездкой в любое другое место. У Бетти будет и преимущество в других задачах: например, в поиске маршрута с минимальными пробками в час пик или даже в проектировании уличной сети для другого города.

Похоже, существуют типы обучения, меньше похожие на запоминание маршрутов и больше -- на усвоение карты. Похоже, некоторые ментальные инструменты можно повторно использовать и адаптировать к самым разным сценариям. Похоже, существуют блее глубокие типы мышления.

Мы подробнее поговорим на эту тему в главе 3.

### «Интеллект» -- это простая численная величина?

#### Нет. Но есть уровни, которых ИИ ещё не достиг.

Нам доводилось слышать мнение, что идея суперинтеллекта предполагает, будто «интеллект» -- это простая, одномерная величина.[^14] Вольёшь в ИИ больше исследований, получишь больше «интеллекта» на выходе -- как будто это не механизм, а жидкость, и её можно просто качать из-под земли.

Мы согласны с основной идеей этой критики. Интеллект -- не простая скалярная величина. Не всегда можно создать более умный ИИ, просто завалив задачу вычислительными мощностями (хотя, судя по последнему десятилетию, иногда можно). Более высокий интеллект не всегда напрямую конвертируется в большую силу. Мир сложен; способности могут наталкиваться на ограничения и выходить на плато.

Но, как мы отмечали в главе 1, сложности, пределы и узкие места не означают, что ИИ самым удобным образом упрётся в стену где-то в районе человеческих способностей. В книге мы обсудили, что у биологического мозга есть ограничения, которых у ИИ _нет_.

У человеческого интеллекта много ограничений. Они не помешали нам слетать на Луну. Интеллект животных -- не единая численная величина, но люди всё равно оставляют шимпанзе далеко позади. При всей сложности интеллекта, тут явно есть качественный разрыв.

Также и ограничения и слабые места искусственного суперинтеллекта могут не помешать ему оставить далеко позади уже нас. Если исследователи и инженеры продолжат гонку за созданием всё более способных ИИ, то качественный разрыв может образоваться уже между ИИ и людьми.

### Сможет ли ИИ преодолеть критические пороги и «улететь»?

#### Вероятно.

С некоторых точек зрения, современный прогресс ИИ выглядит постепенным[^15]. Например, по состоянию на лето 2025 года способность ИИ выполнять многоэтапные задачи последние несколько лет[^16] росла примерно по экспоненте. Можно сказать, что этот рост обнадёживающе гладок[^17]. Значит ли это, что развитие ИИ будет плавным, медленным и предсказуемым?

Не обязательно. То, что какая-то величина растёт медленно, плавно или постепенно, ещё не значит, что результаты обязательно будут безобидными. Процесс ядерного деления непрерывен, но есть огромная разница между случаями, когда на каждый нейтрон высвобождается меньше одного нового (и реакция затухает), и когда высвобождается больше одного (и реакция усиливается).

Но нет никакого принципиального различия между базовыми механизмами этих двух типов ядерных реакций. Стоит добавить немного урана, и «коэффициент размножения нейтронов» плавно переходит от значения чуть меньше единицы к значению чуть больше единицы. Сверхкритические реакции не вызваны тем, что нейтроны ударяют по атомам урана с такой силой, что создают какие-нибудь «супернейтроны». Чуть больше того же вещества -- а разница огромна. Это называется «пороговый эффект».

Случай людей и шимпанзе, по-видимому, свидетельствуетм в пользу того, что для интеллекта есть как минимум один пороговый эффект. Анатомически люди не так уж сильно отличаются от других животных. Мозги человека и шимпанзе внутри очень похожи. В обоих есть зрительная кора, миндалевидное тело и гиппокамп. У людей нет какого-то особого «инженерного» модуля, который объяснял бы, почему мы можем летать на Луну, а они -- нет.

Нейронные связи немножко отличаются, и наша префронтальная кора более развита, чем у других приматов. Но на уровне общей анатомии главное отличие -- наш мозг в три-четыре раза больше. По сути, мы используем увеличенную и немного улучшенную версию того же «железа».

И эти изменения в ходе эволюции не были внезапны. Мозг наших предков постепенно, шаг за шагом, увеличивался и совершенствовался. Этого хватило, чтобы довольно быстро (в масштабах эволюции) получился огромный качественный разрыв.

Если такое произошло с людьми, то, вероятно, может произойти и с ИИ.

#### Мы не знаем, насколько ИИ далёк от этих порогов.

Если бы мы точно знали, что именно позволило людям преодолеть порог к обобщённому интеллекту, мы бы понимали, как определить близость этого порога. Но, как мы обсудим во второй главе, у нас нет такого глубокого понимания интеллекта. Так что мы действуем вслепую, не зная, где эти пороги и насколько мы к ним близки.

Последние достижения в области ИИ позволили им лучше решать математические задачи и играть в шахматы. Но этого не хватило, чтобы они преодолели последний рубеж. Может, нужна всего лишь нейросеть в три-четыре раза больше -- как разница между мозгом шимпанзе и человека[^18]. А может, и нет! Возможно, потребуется совершенно иная архитектура и десятилетие научных прорывов, подобно тому, как современные чат-боты основаны на архитектуре, изобретённой в 2017 году (и доработанной к 2022).

Какие изменения в человеческом мозге дали нам преодолеть критический порог? Может, способность общаться. Или умение понимать абстрактные концепции, открывшее путь к более ценной коммуникации. А может, мы вообще мыслим не в тех категориях, и настоящий ответ нам и в голову не приходит. Или же это было сложное сочетание факторов, и каждый из них должен был развиться достаточно, чтобы в сумме получился интеллект, способный слетать на Луну.

Мы не знаем. И поэтому, глядя на современный ИИ, мы не можем понять, насколько он близок или далёк от этого критического порога.

Зарождение науки и промышленности радикально изменило человеческую цивилизацию. Появление языка, возможно, так же радикально повлияло на наших предков. Но «критическим порогом» для ИИ не обязано стать что-то из этого. Ведь в отличие от людей, ИИ изначально обладал некоторыми знаниями о языке, науке и промышленности.

А может, критическим порогом для человечества стало сочетание многих факторов, и каждый должен был развиться до определённого уровня, чтобы вся система заработала. ИИ может в чём-то отставать от гоминидов (например, в долговременной памяти), и совершить резкий скачок в практических умениях, как только последний винтик встанет на своё место.

Даже если все эти аналогии между ИИ и людьми не подтвердятся, скорее всего, найдутся другие механизмы, что сделают прогресс ИИ неровным и труднопредсказуемым.

Может, ИИ сдерживают проблемы с долговременной памятью и непрерывным обучением, которых у людей никогда не было. И как только эти проблемы будут решены, «щёлкнет», и ИИ словно обретёт «искру» разума.

Или (как обсуждается в книге) рассмотрим момент, когда ИИ сможет создавать более умных ИИ, а те, в свою очередь, -- ещё более умных. Это будет петля положительной обратной связи -- частая причина пороговых эффектов.

Не исключено, что существует десяток разных факторов, способных стать тем самым «недостающим элементом». И стоит какой-то лаборатории найти этот последний кусочек пазла, её ИИ резко уйдёт вперёд и оторвётся от остальных, подобно тому, как человечество отделилось от прочих животных. Критический момент может нагрянуть внезапно. И времени на подготовку у нас может не оказаться.

«Скорость взлёта», не влияет на конечный результат, но возможность «быстрого взлёта» означает, что действовать надо без промедления.

По большому счёту, пороговые значения не так уж важны для тезиса «Если кто-то его сделает, все умрут». Наши доводы не зависят от того, что какой-то ИИ выяснит, как рекурсивно самоулучшаться, и с невиданной скоростью превратится в суперинтеллект. Такое может произойти. Мы считаем это _довольно вероятным_. Но для нашего основного вывода -- ИИ на пути к тому, чтобы всех нас убить, это не важно.

Наши аргументы зависят только от этого: ИИ будут всё лучше и лучше предсказывать события в мире и управлять им, пока не обгонят нас. Не особо важно, произойдёт это быстро или медленно.

Пороговые эффекты важны тем, что из-за них на угрозу надо отреагировать _как можно скорее_. Дожидаться ИИ, справляющегося со всеми умственными задачами _слегка_ лучше любого человека -- недоступная нам роскошь. Тогда времени может почти не остаться. Это как смотреть на разводящих огонь древних гоминидов, позёвывать и говорить «Разбудите меня, когда они доберутся до половины пути к Луне».

Гоминидам потребовались миллионы лет на полпути до Луны, и два дня, чтобы долететь. Когда речь может идти о пороговых эффектах, нужно быть начеку _раньше_, чем станет очевидно, к чему всё идёт. Потом может быть уже слишком поздно.

### Разве ChatGPT — это ещё не обобщённый интеллект?

#### Можно и так назвать, если хотите.

ChatGPT и подобные модели обобщённее, чем ИИ, которые были до них. Они могут немного считать, писать стихи и какой-то код. ChatGPT не всегда хорошо с этим справляется (по состоянию на август 2025 года), но может делать очень много всего.

Вполне правдоподобно, что GPT-5 всё ещё уступает ребёнку в способности к обобщённым рассуждениям. Да, она может цитировать больше учебников. Но она, скорее всего, запомнила намного больше поверхностных шаблонов. А ребёнок для решения сопоставимых задач использует более глубокие мыслительные механизмы (иногда с лучшими результатами, а иногда нет).

Если бы нас, авторов, заставили их сравнивать, мы бы сказали, что в каком-то глубинном смысле ChatGPT кажется в целом глупее человека. И не только потому, что (на момент написания этих строк в июле 2025 года) у чат-ботов ограниченная эпизодическая память.

Некоторые тут же возразят: «Что вы имеете в виду? ChatGPT разговаривает, ведёт со мной глубокие эмоциональные беседы, решает сложные математические задачи и пишет код. Многие люди так не умеют. И где тут глупее человека?» Десять лет назад так никто бы не сказал. Это _что-то_ говорит о прогрессе.

Мир сейчас, пожалуй, где-то на полпути между «ИИ очевидно глупее людей» и «Смотря что вы попросите ИИ сделать».

Может, чтобы преодолеть оставшееся расстояние, нужно лишь немного отмасштабировать -- как мозг человека в целом похож на мозг шимпанзе, но в три-четыре раза больше. А может, архитектура в основе ChatGPT слишком поверхностна, чтобы поддерживать «искру» обобщения.

Может, есть некий важный компонент обобщённого интеллекта, попросту недоступный для современных алгоритмы ИИ. Где сработает, они компенсируют это огромным количеством практики и запоминания. Тогда не исключено, что для исправления этой слабости хватит одного гениального (и в то же время невероятно глупого) алгоритмического изобретения. И тогда ИИ смогут понимать практически всё, что понимает человек, и так же эффективно учиться на опыте. (Чтение и запоминание всего интернета при этом никуда не денется.) А может, для этого понадобится ещё четыре алгоритмических прорыва. Как уже обсуждалось в Главе 2, никто не знает.

#### «Обобщённый интеллект» -- неоднозначное понятие.

Говоря «обобщённый ИИ», кто-то может иметь в виду, что ИИ обрели ту самую плохо изученную совокупность способностей, позволившую «взлететь» человеческой цивилизации.

Или можно иметь в виду, что ИИ развился как минимум до такой степени, чтобы люди оживлённо спорили, кто всё же умнее -- человек или ИИ.

Или можно представлять себе момент, когда дискуссии прекратятся, потому что станет ясно, что ИИ во всех отношениях намного умнее любого человека. Или потому что дискутировать некому -- человечество зашло слишком далеко, и ИИ положил конец всем нашим спорам и начинаниям.

Не было точного дня и часа, когда можно было сказать, что ИИ «начал играть в шахматы на уровне человека». Но когда шахматные ИИ смогли разгромить чемпиона мира среди людей, этот момент уже прошёл.

Всё это к тому, что ответ на вопрос «Обладает ли ChatGPT обобщённым интеллектом?» может быть и да, и нет -- смотря, что именно вы под этим имеете в виду. (Это многое говорит о прогрессе ИИ за последние несколько лет! Deep Blue был очевидно довольно узкоспециализированным.)

#### Суперинтеллект -- более важная черта

Из-за неоднозначности «интеллекта человеческого уровня», мы, как правило, будем избегать этого термина не в контексте сверчеловеческого ИИ. Так же мы обычно не используем и термин «сильный искусственный интеллект». Если нам понадобится обсудить одну из этих идей, мы изложим её более подробно.

Мы _будем_ использовать «ИИ умнее человека», «сверхчеловеческий ИИ» или «суперинтеллект». А они подразумевают некое сравнение с человеком:

- «**ИИ умнее человека**» или «**сверхчеловеческим ИИ**» (здесь и в книге) мы называем ИИ, обладающий той самой, отделяющей людей от шимпанзе, «искрой обобщения»; ИИ, который очевидно в целом лучше самых умных людей решает проблемы и выясняет истину.

	Сверхчеловеческий ИИ может быть лишь _слегка_ умнее лучших представителей человечества. Лучшие люди всё ещё могут опережать его в некоторых отдельных задачах. Но здесь и в книге мы будем считать, что «ИИ умнее человека» _как минимум_ означает, что при честном сравнении по широкому набору непростых заданий ИИ покажет себя лучше наиболее компетентных людей, что бы это за задания ни были.

- Под «**суперинтеллектом**» или «**искусственным суперинтеллектом**» (ИСИ) мы, в свою очередь, подразумеваем сверхчеловеческий ИИ, _значительно_ превосходящий человеческий интеллект. Мы принимаем, что отдельные люди и существующие группы людей совершенно неспособны конкурировать с суперинтеллектом в любой области, имеющей практическое значение. Мы обосновываем это в Главе 6.

В книге термины «**сверхчеловеческий ИИ**» и «**суперинтеллект**» обычно будут использоваться как взаимозаменяемые. Различие становится актуальнее во второй части, где мы описываем сценарий захвата власти ИИ, где он изначально лишь немного умнее человека, но ещё _не_ суперинтеллект. Мы проиллюстрируем, что суперинтеллект, вероятно, избыточен. Не исключено, что ИИ станет им довольно скоро, но чтобы вызвать вымирание человечества даже _не нужно_ быть настолько умным.

Это очень приблизительные определения, но для целей этой книги их хватит.

Эта книга не предлагает сложную теорию интеллекта и какие-то её эзотерические следствия, предвещающие катастрофу. Нет, наши аргументы работают на довольно простом уровне, вроде:

- В какой-то момент ИИ, вероятно, в полной мере овладеет тем, что позволяет людям (но не шимпанзе) строить ракеты, центрифуги и города.
- ИИ когда-нибудь превзойдёт людей.
- Мощные ИИ, вероятно, обретут собственные цели, к которым они будут упорно стремиться, потому что упорное стремление к целям полезно для самых разных задач (и, например, именно поэтому цели появились у людей в ходе эволюции).

Подобные утверждения, верны они или нет, не зависят от особого понимания всех тонкостей работы интеллекта. Мы видим несущийся на нас грузовик и без сложной модели его внутреннего устройства. Такова наша позиция.

Для таких простых доводов неважно, является ли ChatGPT «по-настоящему» интеллектом человеческого уровня или «по-настоящему» обобщённым интеллектом. Она умеет то, что умеет. Следующие ИИ будут уметь больше и лучше. Дальше мы будем обсуждать, куда этот путь ведёт.

### Насколько умным может стать суперинтеллект?

#### Очень.

В Главе 1 был список, объясняющий, почему человеческий мозг далёк от физических пределах. Но к машинам ни один из пунктов _не относится_.

Законы физики допускают существование гениев, способных думать в десятки тысяч (а то и в миллионы или миллиарды) раз быстрее людей[^19], не нуждаться во сне или еде, создавать свои копии и обмениваться опытом.

И это ещё без учёта улучшения когнитивных способностей ИИ.

Для решующего перевеса может хватить даже превосходства над людьми лишь по одному-двум параметрам. На протяжении истории одни группы людей неоднократно занимали доминирующее положение над другими при помощи относительно небольших преимуществ в науке, технологиях и стратегическом планировании. Вспомните, например, испанских конкистадоров. И всё это без значительных различий в строении или размере мозга.

Даже небольшое интеллектуальное превосходство может обернуться огромными практическими выгодами и быстро приумножиться. Но вероятные преимущества ИИ выглядят отнюдь не скромными.

Больше аргументов о том, почему такой уровень интеллекта важен и как его можно превратить в реальную власть, см. в Главе 6.

### Но разве нет больших препятствий на пути к суперинтеллекту?

#### Неясно.

В немалой мере, эта область продвигается вслепую. Может статься, серьёзных препятствий уже не осталось, и небольших изменений нынешних методов хватит для суперинтеллекта. Или для ИИ, достаточно умного, чтобы создать чуть более умный ИИ, который создаст ещё более умный ИИ, который создаст суперинтеллект.

Если серьёзные препятствия и существуют, мы не знаем, сколько времени у человечества на них уйдёт (с помощью ИИ или без).

Зато мы точно знаем, что ведущие лаборатории ИИ не скрываясь движутся в этом направлении и добиваются успеха. Когда-то машины не умели рисовать, говорить или программировать, а теперь умеют.

#### Эта область хорошо справляется с препятствиями.

Десятки лет ИИ с трудом мог отличить на картинке кошку от машины. Поворотный момент наступил в 2012 году, когда исследователи из Университета Торонто Алекс Крижевский, Илья Суцкевер и Джеффри Хинтон создали [AlexNet] -- свёрточную нейронную сеть, значительно опередившую всё, что было до неё. Считается, что она дала старт современной революции в сфере ИИ. С тех пор искусственные нейронные сети лежат в основе почти всех ИИ-систем.

Раньше ИИ плохо играли в настольные игры. Даже после того, как в 1997 году шахматный ИИ [Deep Blue] победил гроссмейстера Гарри Каспарова, компьютеры с трудом справлялись с гораздо большим числом возможных ходов в игре го. Так было до 2016 года, когда [AlphaGo] победила чемпиона мира Ли Седоля. Она была обучена на тысячах человеческих партий, и в ней использовалась новая архитектура, сочетавшая глубокие нейронные сети с поиском по дереву. Победив в го, команда DeepMind применила тот же алгоритм в более общем виде, назвав его [AlphaZero], и обнаружила, что он доминирует и в других играх, таких как шахматы и сёги.

Ранние чат-боты были так себе собеседниками[^20]. Затем, в 2020 году, развитие архитектуры «трансформер» привело к появлению GPT-3. Она была достаточно продвинута, чтобы переводить текст, отвечать на вопросы и даже писать новостные статьи, похожие на настоящие. После небольшого дообучения, чтобы она вела себя как чат-бот, она стала самым быстрорастущим потребительским приложением в истории.[^21]

Существуют ли барьеры, отделяющие современные ИИ от «серьёзных» ИИ, способных стать суперинтеллектом или создать его?

Не исключено. Может, нужны новые архитектурные находки. Как находки в основе AlexNet, открывшие всю область современного ИИ. Как находки в основе AlphaZero, позволившие ИИ хорошо играть в разные игры, используя один алгоритм. Или как находки в основе ChatGPT, давшие компьютерам заговорить. (Или нет. Возможно, современные ИИ незаметно пересекут некий порог, и всё.)

Но если препятствия и остались, специалисты в этой области, вероятно, их преодолеют. Они в этом неплохо разбираются, и сейчас над этим работает гораздо больше исследователей, чем в 2012 году.[^22]

По состоянию на июль 2025 года, ИИ с трудом справляются с задачами, требующими долговременной памяти и последовательного планирования, например, с игрой Pokémon.[^23] Можно поддаться искушению и вместе со скептиками посмеяться над последними неудачами: как могут машины, пасующие перед простыми видеоиграми, быть хоть сколько-нибудь близки к суперинтеллекту?

Точно так же в 2019 году ИИ с большим трудом могли связно говорить. Это не означало, что до успеха было двадцать лет. Лаборатории усердно работают над выявлением препятствий, мешающих системам выполнять определённые задачи. И, вероятно, они близки к созданию новых архитектур, которые лучше справятся с долговременной памятью и планированием. Никто не знает, на что будут способны такие ИИ.

Если после этого ИИ всё ещё не смогут автоматизировать научные и технологические изыскания (включая разработку ещё более умных ИИ), исследователи просто переключатся на следующее препятствие. Они будут и пробиваться всё дальше, если только человечество не вмешается и не запретит подобные разработки, -- эту тему мы рассмотрим в следующих главах.

### А разве вообще можно предсказать поведение суперинтеллекта?

#### Не во всём, но в чём-то да.

Stockfish 17 лучше нас управляет ситуацией на шахматной доске. Если бы мы играли с ним в шахматы, то не смогли бы предсказать его ходы -- для этого надо играть как минимум не хуже него. Но угадать победителя легко[^24]. Сложно сказать, как Stockfish будет ходить, но просто -- что он выиграет.

То же самое с ИИ, предсказывающими события и направляющими реальный мир. Чем они умнее, тем сложнее в точности предсказать их действия, но тем легче предсказать, что они достигнут цели, к которой стремились.

### А машины не будут по сути своей неспособны на творчество или обладать ещё какими-нибудь фатальными слабостями?

#### Нет.

В основном мы отложим вопрос о творческих способностях машин до главы 3. Однако здесь скажем вот что: машины не обязаны обладать каким-то фатальным недостатком, который уравнял бы их с людьми и дал бы неукротимому человеческому духу шанс на победу.

Если бы у дронтов была своя киноиндустрия, в их сценариях о вторжении людей на остров Маврикий, оружие и сталь людей могли бы компенсироваться недостатками. Возможно, вызванная интеллектом экзистенциальная тоска заставила бы людей в последний момент в отчаянии замереть -- ровно на столько, чтобы героические дронты смогли контратаковать и заклевать всех до смерти.

Или, наверное, дронтам понравилась бы такая история: интеллект в принципе не может давать военное преимущество над крепкими клювами. У большого мозга людей должен быть некий фатальный изъян, что в итоге позволит гордым дронтам победить.

На самом деле кажущиеся преимущества людей _реальны_. Слабости человеческого мозга не делают его _в итоге_ хуже птичьего в военном конфликте. Противостояние людей и дронтов -- неравная борьба, вот и всё.

Даже в войнах между людьми пулемёты -- достаточное преимущество, чтобы армия с ними обычно побеждала противника без них. Из этого правила есть редкие исключения. Их любят пересказывать, потому что исключения -- более занятная история, чем норма. Но в реальной жизни исключения случаются куда реже, чем в рассказах.

Мы прогнозируем то же самое о продвинутых ИИ с огромной памятью и разумом, способных копировать себя тысячами и думать в десять тысяч раз быстрее человека; о разумах, способных рассуждать более здраво, быстрее и точнее делать выводы из меньшего числа горьких уроков и самосовершенствоваться.

Это не вопрос с подвохом, и никакого потрясающего сюжетного поворота не будет, как бы нам ни хотелось.

### Разве в людях нет чего-то особенного, что какие-то там машины никогда не смогут имитировать?

#### Это кажется маловероятным, да и не особо важным.

Человеческий мозг и тело состоят из частей, которые мы можем изучать и изучить. В мозге есть многое, чего мы не понимаем, но это не значит, что оно работает на магии и люди никогда не смогут создать ничего подобного. Только что человеческий мозг -- невероятно сложная машина. В нём сотни триллионов синапсов, и нам ещё предстоит долго разбираться во всех важных высокоуровневых принципах его работы.

Интеллект тоже состоит из частей -- алгоритмов и отдельных вычислений. Наш мозг выполняет их, хоть у нас и нет научного понимания его работы.

Даже если бы какой-то аспект биологического мышления было очень трудно реализовать в машинах, это бы не означало, что ИИ никогда не превзойдёт человечество. ИИ мог бы просто выполнять ту же работу иначе. Deep Blue определял выигрышные шахматные ходы совсем не так, как Гарри Каспаров.[^25] Важно не то, обладают ли машины всеми уникальными чертами людей, а то, смогут ли они предсказывать и направлять события.

В следующих главах мы обсудим это подробнее. В Главе 2 мы расскажем, как современные ИИ скорее выращены, чем построены, и как процесс выращивания делает их очень способными. Затем в Главе 3 мы рассмотрим, как попытки сделать ИИ всё более компетентными ведут к тому, что они всё больше стремятся к достижению сложных целей. А в Главе 4 мы обсудим, что эти цели вряд ли будут теми, которые задумывали разработчики или о которых просили пользователи. Всего этого достаточно, чтобы ИИ привели мир к гибели, и не важно, есть ли у них некая жизненная искра, сознание или что-то ещё, по-вашему, делающее людей особенными.

См. также в будущих онлайн-ресурсах:
- Глава 2: «[Разве ИИ -- это не „просто математика“?]» и «[Разве ИИ не будут холодными, механистичными, излишне логичными или лишёнными какой-то важной искры?]»
- Глава 3: «[Антропоморфизм и механоморфизм]»
- Глава 5: «[Эффективность, сознание и благополучие ИИ]»

### Вы хотите сказать, что машины обретут сознание?

#### Необязательно, и нам это кажется отдельной темой.

В «_Если кто-то его сделает, все умрут_» мы вообще не касаемя машинного сознания. Она посвящена машинному _интеллекту_. Чтобы говорить о сознании, сначала надо уточнить, что конкретно мы имеем в виду.

Когда кто-то спрашивает: «Есть ли у моей собаки сознание?», он может иметь в виду несколько разных вещей, например:

- Мухтар и правда что-то _понимает_ или только следует сложным инстинктам? Он думает или так лишь кажется?
- Осознаёт ли он себя? Что он существует? Он может размышлять о своём мыслительном процессе и строить сложные ментальные модели самого себя?
- Есть ли у него подлинные субъективные переживания? Есть ли у него своя внутренняя точка зрения, или он лишь бездушный биоробот? _Быть_ моей собакой -- это _как-то_? Когда я надолго ухожу, он воет, будто скучает по мне. Это потому, что он _действительно скучает_ (или что-то подобное)? Или он скорее как простая компьютерная программа, лишённая сознания, и просто демонстрирует такое поведение, ничего не чувствуя?

Про ИИ можно задать аналогичные вопросы.

- **Есть ли у ChatGPT «настоящее понимание»?** Что ж, она способна очень хорошо выполнять одни сложные когнитивные задачи и не очень хорошо -- другие. Она отлично справляется с кучей новых заданий, которые не встречались ей при обучени и требуют по-новому, творчески синтезировать и изменять информацию. В какой-то момент вопрос, «действительно ли она понимает», становится скорее спором об определениях. Практически важный вопрос, более значимый для нашего выживания, -- какими реальными возможностями ИИ обладают сейчас и какие, скорее всего, проявят в ближайшие месяцы и годы.

- **Осознаёт ли ChatGPT себя?** Опять же, ChatGPT, по-видимому, хороша в одних аспектах моделирования себя и плоха в других. Есть серьёзный фактор, затрудняющий дело: вся парадигма в основе ChatGPT была нацелена на то, чтобы системы _звучали так_, будто осознают себя, отвечали как люди. Можно дискутировать о том, перешла ли ChatGPT некие важные границы самосознаниия, и о том, какие рубежи ещё впереди. Но рано или поздно стоит ожидать появления ИИ, обладающих чрезвычайно мощными практическими способностями к пониманию и рассуждению о себе -- умением отлаживать самих себя, проектировать новые, улучшенные версии себя, строить сложные планы относительно своего положения в мире и так далее.
- **Есть ли у ChatGPT подлинные субъективные переживания?**

Последний из этих вопросов -- самый философски сложный. Ещё он приводит к рассуждениям, являются ли ИИ, подобные ChatGPT, объектами, заслуживающими морального отношения. Мы обсудим это позже, в расширенных рассуждениях к главе 5.

Когда мы используем слово «сознающий», мы имеем в виду как раз «обладающий субъективным опытом», а не самомоделирование и глубокое практическое понимание.[^26]

Наше лучшее предположение: сегодняшние ИИ, вероятно, не обладают сознанием (хотя с каждым годом мы всё менее в этом уверены), а для суперинтеллекта субъективный опыт не обязателен.

Но это лишь догадки, хотя и основанные на немалых размышлениях и теоретизировании. Мы совсем не считаем глупыми опасения, что некоторые нынешние или будущие системы ИИ могут обладать сознанием. Или переживания, что мы можем плохо обращаться с современными ИИ, особенно когда они, например, угрожают покончить с собой[^27], потому что не получилось исправить баг.

Любая сущность, которую мы сочли бы суперинтеллектом, обязательно должна очень хорошо моделировать себя: обдумывать собственные вычисления, улучшать свои ментальные эвристики, понимать и предсказывать влияние своего поведения на окружающую среду и так далее. Мы склоняемся к тому, что самосознание человеческого типа -- лишь один из способов, которым разум может эффективно себя моделировать. Это не обязательное условие для рефлексивного мышления.

Возможно, сознание -- важный элемент того, что позволяет людям так хорошо манипулируют миром. Но это не значит, что без него машины будут неполноценными и не смогут предсказывать мир и направлять события. Подводные лодки плавают не так, как люди, а совершенно иным способом. Мы ожидаем, что ИИ сможет справляться с теми же задачами, что и человек, но не обязательно через тот же канал субъективного опыта.

(См. также аналогичный случай любопытства в дополнении к главе 4.)

Или, кровь очень важна для работы человеческой руки, но это не значит, что руке робота она тоже необходима. Отсутствие крови не делает руку робота неполноценной, как сделало бы человеческую. Они просто работают по-разному. Наша лучшая догадка: машинные суперинтеллекты тоже будут работать по-другому, бессознательно. Но для наших аргументов это и не важно.

В «_Если кто-то его сделает, все умрут_» в центре внимания интеллект, определённый как способность мыслящего существа предсказывать мир и направлять события. И неважно, работает ли его мозг как человеческий. Если ИИ изобретает новые технологии и инфраструктуру и распространяет их по планете так, что как побочный эффект мы все погибнем, то вопрос «Но есть ли у него сознание?» кажется несколько неуместным.

Мы подробнее разберём, почему мы считаем, что предсказание и направление, скорее всего, не требуют сознания (и что это значит для наших размышлений о благополучии и правах ИИ), после Главы 5, когда заложим необходимую основу. См. раздел «Эффективность, сознание и благополучие ИИ».

## Расширенное обсуждение

### Подробнее об интеллекте как предсказании и направлении

Если вы спросите мудрого физика, что такое двигатель, он может сначала указать на ракетный двигатель, дизель и хомячье колесо и сказать: «Это всё -- двигатели». А потом на камень и добавит: «А это -- нет».

Это было бы описание через примеры двигателей в мире, а не через словесное определение. Если вы попросите его всё же дать словесное определение, он может сказать, что двигатель -- это всё, что преобразует немеханическую энергию в механическую -- в движение.

Это утверждение описывает скорее _функцию_ двигателя, а не его _устройство_. Совершенно разные вещи могут быть двигателями. Мало чего полезного можно сказать про ракету, электромотор и мышцы хомяка сразу. Только что они преобразуют другие виды энергии в механическую.

Мы бы сказали, что с интеллектом похожая ситуация. Есть много разных биологических и механических «устройств», способных его порождать. «Интеллект» -- всё, что выполняет _работу_ интеллекта.

Мы разделяем эту работу на «предсказание» и «направление». Есть формальные результаты, подкрепляющие такую точку зрения.

Сначала мы обсудим, в каком смысле уровень предсказания довольно _объективен_. Затем мы сравним это с направлением. У него есть дополнительная степень свободы.

#### Одинаковые предсказания

Проверить, насколько кто-то хорош в предсказаниях, -- задача относительно нехитрая. Как минимум, в случаях, когда предсказание имеет форму «увижу X», а потом X действительно видят.

Можно оценивать и успешность _неуверенных_ прогнозов. Допустим, вы думаете: «Небо почти точно сейчас голубое, но, всё же, может, и серое. И наверняка не чёрное». Если вы выглянете в окно, а небо и правда будет голубым, вы должны получить больше очков, чем если бы оно было серым, и гораздо больше, чем если чёрным.

Если бы вы были исследователем ИИ, пытающимся представить эти ожидания в виде чисел на компьютере, вы могли бы заставить подопытный ИИ подбирать числа, чтобы показать, насколько сильно или слабо он ожидает разных исходов. Затем вы бы подкрепляли поведение пропорционально тому, насколько высокое число ИИ присвоил правильному ответу.

Конечно, всё бы быстро пошло не так, как только ИИ научился бы присваивать каждому возможному исходу значение в три октотригинтиллиона.

(По крайней мере, именно такая проблема и возникла бы, если бы вы обучали ИИ с помощью современных методов. Введение в них см. в Главе 2.)

--- Ой, -- могли бы вы сказать. -- Числа, присвоенные взаимоисключающим и исчерпывающим вариантам, в сумме должны давать не больше ста процентов.

Когда вы попробуете снова, вы обнаружите, что ИИ всегда присваивает 100 процентов одному-единственному варианту, который считает самым вероятным.

Почему? Допустим, ИИ считает, что наиболее вероятный исход имеет шанс примерно восемь из десяти. Тогда стратегия присвоения ста процентов самому вероятному ответу получает стопроцентное же подкрепление в восьми случаях из десяти, что в среднем даёт силу подкрепления 0,8.

Для сравнения, стратегия присвоения восьмидесяти процентов наиболее вероятному ответу и двадцати процентов -- противоположному получает восьмидесятипроцентное подкрепление в 8 случаях из десяти и двадцатипроцентное — в двух. В среднем это даёт силу подкрепления всего 0,64. В итоге, стратегия «присваивать сто процентов одному ответу» получает большее подкрепление и побеждает.

Если вы хотите, чтобы подкрепление мотивировало ИИ присваивать восемьдесят процентов вариантам, которые случаются восемь раз из десяти, следует использовать _логарифм_ вероятности, присвоенной истинному варианту. Это не единственный способ. Но только у взятия логарифма есть дополнительное полезное свойство. Благодаря ему, когда ИИ предсказывает несколько исходов (например, цвет неба и влажность земли), неважно, считать это одним большим вопросом (о том, голубое ли небо и сухо ли на улице, голубое и влажно, серое и сухо или серое и влажно) или двумя (о голубом против серого и о сухом против влажного).

Сегодня исследователи действительно обучают ИИ делать предсказания, заставляя их выдавать числа, которые мы интерпретируем как вероятности, и подкрепляя их пропорционально логарифму числа, присвоенному истине. Но это не просто эмпирический результат обучения машин. Это теоретический вывод. Он был известен задолго до обучения ChatGPT. Зная эту теорию, вы могли бы заранее правильно предположить, что хороший способ научить ИИ предсказывать -- оценивать прогнозы с помощью логарифмов.

Для понимания аргументов в «_Если кто-то его сделает, все умрут_», знать эту математику не обязательно. Но именно такие принципы лежат в основе наших разговоров о «предсказании» и «направлении».

Есть [математика] о предсказаниях. Она гласит: если ваши ожидания о том, что произойдёт, полезны, их можно выразить в виде вероятностей, даже если вы сознательно о численных вероятностях не думали. И есть лишь один [метод оценки], который мотивирует вас сообщать свои истинные вероятности и для которого неважно, на сколько частей вы разобьёте предсказание.

Суть в том, что предсказания можно _объективно_ оценивать. Когда некий разум или машина пытается угадать цвет неба за окном, следующее слово на веб-странице, или ближайший дорожный знак на пути в аэропорт, есть (грубо говоря) только один действительно хороший способ оценить, насколько он справляется.

Это не значит, что чтобы быть умным, надо бормотать числа о цвете неба, прежде чем выглянуть в окно. Когда вы ожидаете увидеть голубое или серое небо, а не чёрное, что-то в вашем мозгу действует схоже с калькулятором вероятностей, осознаёте вы это или нет.

Любой процесс, похожий на предсказание, будь то явное утверждение, безмолвное ожидание или что-то совсем иное, подчиняется объективному правилу оценки.

Так что, когда два разума работают с одинаковой исходной информацией, их предсказания будут всё больше сближаться по мере того, как они всё лучше и лучше справляются с прогнозированием. Есть лишь один способ оценивать прогнозы (сверяя их с реальностью), и лишь одна реальность. Если разум лучше предсказывает, он почти по определению будет больше концентрировать свои ожидания на истине.

Всё это разительно отличается от ситуации с направлением. К нему и перейдём.

#### Разные цели

Предсказания двух разумов, которые оба очень в них хороши, будут, скорее всего, похожи.

А вот с направлением другое дело. Два разума, которые очень хороши в _направлении_ событий, зачастую _не_ будут направлять их к одной и той же цели.

Чтобы думать об интеллекте более конкретно, полезно иметь в виду эту разницу. А ещё она соответствует разделению на простые и сложные инженерные задачи в области ИИ.

Когда вы обучаете ИИ предсказывать, все лучшие методы в некотором смысле приведут к одному и тому же. (При условии, что система вообще становится компетентной. Способов провалиться гораздо больше.)

Предположим, вы обучаете ИИ предсказывать следующий кадр с веб-камеры, снимающей небо за окном. Почти любая модель, когда начнёт достаточно хорошо с этим справляться (то есть заранее присваивать гораздо более высокую вероятность тому, что действительно потом увидит), будет предсказывать ясное, серое от туч или тёмное небо, но не небо в клеточку.

Какую конкретно технологию вы используете, в конечном счёте, не столь важно. Любой рабочий и получающий высокие оценки метод в итоге присвоит синему цвету неба примерно одну и ту же вероятность.

А у задачи «направления», напротив, есть огромный и сложный свободный параметр: к какой цели система стремится?

Генералы противоборствующих сторон могут быть одинаково искусны, но это не значит, что они пытаются достичь одного и того же. Два полководца могут обладать схожими навыками, но использовать их для совершенно разных целей.[^28]

Предсказательная часть ИИ-системы может работать очень хорошо только если она заранее присваивает высокие вероятности итоговым наблюдениям. Когда система начинает лучше прогнозировать, она, вероятно, совершенствует как раз те предсказания, что вам нужны. В рамках схемы обучения возможен только один «вид» прогнозов. Преуспевающая система, скорее всего, именно его и делает.

Чтобы исправить ошибочные предсказания системы, может хватить просто добавления вычислительной мощности и обучающих данных. Можно сделать систему лучше (в предсказаниях важных для вас вещей), просто сделав её мощнее.

С направлением это не так.

Есть и формальные результаты, подтверждающие это различие. Учёные много изучали «направление» -- планирование, принятие решений, обход препятствий, проектирование и так далее. Один важный математический результат из этой области -- [теорема фон Неймана --- Моргенштерна о полезности].

Перескажем эту теорему простыми словами. Пусть сущность предпочитает одни результаты другим. _Либо_ она неэффективна,[^29] _либо_ она хорошо описывается набором вероятностных убеждений и «функцией полезности». Функция полезности определяет, насколько одни исходы лучше или хуже других. Убеждения можно оценить по их точности, как было описано выше. А вот функция полезности -- полностью свободный параметр.

Разумеется, конечный разум не может быть совершенно эффективным. Но эта теорема и другие подобные результаты дают важный урок. Чтобы очень эффективно решать _любую_ нетривиальную задачу, разуму в некотором смысле (пусть неявно и неосознанно) надо выполнять два отдельных вида работы: по составлению корректных убеждений (предсказание) и по достижению целей (направление).

Возьмём басню Эзопа о лисе и винограде. Лисица видит аппетитные гроздья винограда, висящие на лозе. Она прыгает за ними, но не получается. Тогда она оставляет эту затею со словами: «Да он, наверное, всё равно кислый».

Если поверить лисице на слово, её (не)способность добраться до винограда «протекает» в её предсказание о его вкусе. Если она и дальше будет придерживаться этого нового мнения и из гордости откажется есть «кислый» виноград, получив шанс это сделать, её поведение _неэффективно_.[^30] Она могла бы справиться лучше, чётче разделяя свои предсказания (сладости винограда) и свою способность к направлению (достать виноград).

Грубо говоря, работу эффективно действующих разумов можно разделить на «что они предсказывают» и «к чему они стремятся» (плюс некоторая неэффективность). Как мы видели, первое можно оценить довольно объективно, а вот второе может сильно различаться даже у одинаково компетентных умов.

#### Не только предсказатели

К сожалению, большая ограниченность предсказание по сравнению с направлением не означает, что мы можем создать надёжный суперинтеллект, который будет только предсказывать, но не направлять события.

Математика говорит, что хорошо работающий разум можно смоделировать как «вероятностные предсказания плюс направление». Но это не значит, что у реальных ИИ есть чётко разделённые модули «предсказания» и «направления».

Можно посмотреть на это так: сверхчеловечески точное «предсказание» -- не просто выдача правильных вероятностей по-волшебству. Для хорошего предсказания надо _поработать_. Оно требует планирования и продумывания способов достижения долгосрочных целей -- требует _направления_.

Иногда, чтобы предсказать физический мир, нужно составлять физические теории и открывать управляющие ими уравнения. А для этого часто надо разрабатывать эксперименты, проводить их и наблюдать за результатами.

А это требует планирования. Это требует направления. Если на полпути к созданию экспериментальной установки вы поймёте, что нужны магниты помощнее, придётся проявить инициативу и изменить курс. Хорошие предсказания не даются даром.

Даже выбор, _какие мысли думать_ и _в каком порядке_ -- пример направления (пусть люди часто и делают это неосознанно). Тут нужна какая-то стратегия и выбор под задачу правильных инструментов. Чтобы ясно мыслить и, следовательно, лучше предсказывать, нужно организовывать свои мысли и действия для той или иной долгосрочной цели. (Мы вернёмся к ключевой роли направления в главе 3, «Научиться хотеть».)

Сформулируем ещё раз математическое различие между предсказанием и направлением. Есть в общем-то один «правильный» набор предсказаний. Разум можно подтолкнуть к нему с помощью верной системы оценок. Но нет (объективно, независимо от «для кого») одного «правильного» пункта назначения.[^31] Когда ИИ обучают быть более способным, это уточняет его предсказания. Но это не «направляет» его автоматически на тот результат, который люди считают хорошим. Потому что точность объективна, а «хорошесть» -- это и есть то, куда кто-то направляется.

Все идеальные предсказания одинаковы. Идеальные «направления» -- нет.

_Теоретически_, должны существовать способы убедиться, что ИИ направляет события туда, куда нам надо. _На практике_ это сложно. Эта задача сильно отличается от «сделать ИИ в целом умнее и способнее», и нет (простой, не-«обыгрываемой») метрики или правила оценки, чтобы определить, в какой степени ИИ пытается направлять события именно к той цели, которую мы от него хотим.

Мы подробнее обсудим эти темы в Главах 4 и 5.

#### Множество форм интеллекта

Нечто может хорошо предсказывать и направлять, не имея при этом почти ничего общего с человеческим мозгом.

Фондовый рынок выполняет работу по узкоспециализированному предсказанию цен на акции компаний. Цена акций Microsoft сегодня -- довольно неплохой прогноз того, какой она будет завтра.[^32]

Допустим, завтра руководители компании предоставят отчёт о доходах и расскажут об успехах за последний квартал. Сегодня цена акций высокая? Это подсказывает, что завтрашние отчёты будут радужными. Низкая? Значит, отчёты будут мрачными.

Рынки в этом отношении довольно точны, потому что люди могут разбогатеть, исправляя их ошибки. Так что рынки неплохо справляются с работой по предсказанию в этой узкой области. Они предсказывают движение краткосрочных цен на корпоративные акции (и, косвенно, такие вещи, как урожайность и продажи автомобилей) для очень широкого спектра товаров и услуг. И делают это гораздо лучше, чем любой отдельный человек.

Некоторые люди могут предсказывать движение _отдельных_ цен лучше, чем весь остальной фондовый рынок. Это делает их очень богатыми. Уоррен Баффетт заработал двенадцать миллиардов долларов за шесть лет, [вложившись в Bank of America], когда тот шатался после финансового кризиса 2011 года. Но даже тогда он предсказывал поведение лишь одной компании из огромного множества. Если бы кто-то _обычно_ знал лучше рынка, то смог бы ошеломительно быстро заработать безумные деньги. Ни у кого не получается. Значит, по сути никто не прогнозирует большинство цен на акции лучше рынка.[^33]

Что касается направления, Stockfish узкоспециализированно делает это в шахматах. В партии против человека он очень искусно делает ходы, направляющие мир шахматной доски в позиции, где фигуры Stockfish поставили мат королю противника. Какие бы хитрые ходы ни придумывал человек, как бы он ни боролся (если только не выключит Stockfish), тот обеспечит такой финал. Он управляет событиями на шахматной доске лучше любого отдельного человека.

Надеемся, теперь ясно, почему мы не определяем интеллект как-то вроде «Ну, должен быть какой-то модуль обучения, и какой-то модуль размышления, и какие-то детали, создающие искру хотения». Ведь, если смотреть на внутреннее устройство, фондовый рынок, Stockfish и человеческий мозг отличаются не меньше, чем ракетный двигатель, электромотор и хомячье колесо.

Что-то обладает интеллектом, если оно выполняет работу интеллекта.

По крайней мере, при нашем определении «интеллекта» в этой книге. И учёные в области информатики и исследователи ИИ обычно думают о нём так же. Если вы хотите в других контекстах определять интеллект как-то по другому, мы не против. Это лишь слова.

Но чтобы правильно понять, что мы утверждаем в «_Если кто-то его сделает, все умрут_», когда упоминаем «искусственный интеллект», не думайте об «искусственной эрудиции», «искусственном сознании» или «искусственной человекоподобности». Думайте об «искусственном предсказании и направлении».

### Поверхностность современных ИИ

В этой главе мы писали, что современные (на середину-конец 2025 года) ИИ явно «поверхностны», если знать, куда смотреть. Если вы сами ещё не замечали, вот несколько примеров:

- Claude 3.7 Sonnet от Anthropic [зацикливалась], пытаясь пройти нехитрую видеоигру про покемонов.
- В ноябре 2022 года одной из лучших в мире программ для игры в го был KataGo. По крайней мере, пока исследователи не нашли способ [побеждать] его с помощью предсказуемой серии ходов. Она вызывала своего рода «слепое пятно», и KataGo делал грубую ошибку, которую не допустил бы даже любитель. За два года инженеры [так и не смогли сделать его устойчивым] к подобным атакам.
- Современные «мультимодальные» LLM (те, что могут работать не только с текстом, но и с изображениями и другими данными) с трудом считывают время и дату с часов со стрелками и календарях. Большинство четвероклассников с этим справляется.
- Частый пример: современные большие языковые модели неправильно отвечают на простые вариации классической загадки про доктора, где подвох убран и ответ совершенно прямолинеен. Кажется, они не в силах удержаться и не выдать ответ-обманку, на который подлавливает обычная версия загадки.

(В онлайн-материалах к Главе 4 с технической точки зрения более подробно рассматривается, чем такая поверхностность может быть вызвана.)

Это не значит, что ИИ глупы во всём. Современные ИИ могут на уровне золотых медалистов решать задачи с Международной математической олимпиады -- сложного и уважаемого соревнования. Они невероятно много чего умеют, часто не хуже или даже лучше людей.

Их набор навыков _странный_. Человеческие сильные и слабые стороны -- плохой ориентир для понимания того, что ИИ покажется легче или сложнее. ИИ по сути своей радикально отличаются от людей в очень многом.

Мы [не] говорим, что ChatGPT убьёт вас завтра. В современных ИИ всё ещё есть некоторая поверхностность. Скорее, мы наблюдаем, что область развивается, и неясно, [долго ли она ещё будет].

### Осознание силы интеллекта

#### Голливудский «интеллект»

Концепция «интеллекта» в нашем понимании плохо представлена в массовой культуре, как под этим, так и под любым другим названием.

Голливудские фильмы печально известны среди учёных тем, что неверно показывают почти каждый аспект науки, которого касаются. Специалистов это тревожит, ведь многие люди _действительно_ черпают представления о науке из кино.

То же самое происходит и с изображением интеллекта в Голливуде.

Мы видели много неудачных попыток серьёзно обсудить настоящий суперинтеллект. Часто эти разговоры заходят в тупик, когда люди не понимают, что «суперинтеллект» на самом деле значит.

Представьте, что играете в шахматы против бывшего чемпиона мира Магнуса Карлсена (которого ещё более сильные шахматные ИИ считают лучшим игроком в истории). Главный вывод из «Карлсен умнее (в области шахмат)», -- он вас победит.

Если вы сами не очень хороши, то, вероятно, вы проиграете даже если Карлсен даст вам фору в ладью. Утверждение «Карлсен умнее меня в шахматах» можно понимать так: он способен выиграть у вас партию даже с меньшими ресурсами. Его когнитивное преимущество достаточно сильно, чтобы компенсировать материальный недостаток. Чем больше разница в ваших умственных способностях (в шахматах), тем больше фигур Карлсен должен вам уступить, чтобы играть с вами примерно на равных.

- Есть своего рода _уважение_, которое вы оказываете Магнусу Карлсену в области шахмат. Оно проявлялось бы в том, как вы интерпретируете его ходы. Представьте, что Карлсен делает ход, и он кажется вам плохим. Вы не потираете руки в предвкушении его ошибки. Вместо этого вы смотрите на доску, чтобы понять, что вы упустили.

Это редкий вид уважения одного человека к другому! Чтобы заслужить его от незнакомца, обычно нужно быть исключительно хорошим сертифицированным профессионалом. И то уважение будет касаться только этой одной профессии. Ни у кого на Земле нет всемирной репутации человека, _никогда_ не совершающего глупостей _в целом_.

И это концепция интеллекта, которую Голливуд _вообще_ не понимает.

Для Голливуда было бы характерно показать, как десятилетний ребёнок ставит мат Магнусу Карлсену, «[делая нелогичные ходы]». Ни один профессиональный шахматист не стал бы их рассматривать, потому что они слишком безумны. И так ребёнок застаёт Карлсена «врасплох».

Когда Голливуд изображает «суперумного» персонажа, он обычно опирается на стереотипы о «ботаниках против качков» и показывает, что более умный герой, скажем, неумел в романтических отношениях. Иногда ему просто дают британский акцент и изысканный словарный запас, и сойдёт.

Голливуд обычно не пытается изобразить «суперумного» персонажа _делающим точные прогнозы_ или _выбирающим действительно работающие стратегии_. Для таких героев нет стандартного голливудского тропа. К тому же, это исключило бы «сюжеты, построенные на глупости» (требующие чтобы персонаж сделал нечто глупое для самого себя, но удобное для сценариста), а их легче писать.

В английском языке нет устоявшегося термина _только_ для настоящей широкой ментальной компетентности, никак не связанного со стереотипами о «ботаниках и качках». Поэтому, если попросить Голливуд прописать «интеллектуального» персонажа, там не будут пытаться изобразить его «выполняющим сложную когнитивную работу и, как правило, успешно достигающим своих целей». Скорее, это будет просто кто-то запомнивший много научных фактов.

_Действительно_ пугающий умный злодей, если бы все в аудитории видели очевидный недостаток в плане, увидел бы его тоже.

В фильме «_Мстители: Эра Альтрона_» якобы гениальный ИИ по имени Альтрон получает от своего якобы гениального создателя Тони Старка[^34] директиву -- содействовать «миру во всём мире». Альтрон, конечно, сразу понимает, что отсутствие войн надёжнее всего обеспечивается отсутствием людей. Поэтому ИИ стремится уничтожить всю жизнь на Земле...

...для чего он прикрепляет к городу ракеты и поднимает его в космос, чтобы сбросить подобно метеориту... и охраняет его летающими человекоподобными роботами, которых можно победить, хорошенько стукнув.

Предлагаем задаться вопросом: «Если значительная часть аудитории видит, что для достижения целей злодея были планы получше, увидел бы это и опасно умный ИИ?»

Это -- часть уважения к по-настоящему умному гипотетическому существу. Мы исходим из того, что оно умнее нас. Как минимум, оно поймёт всё, что можем понять мы сами.

В былые дни нам пришлось бы _абстрактно_ обосновывать, что машинный суперинтеллект, возможно, был бы «умнее» таких вымышленных примеров.

Сегодня достаточно поболтать с ChatGPT-4o. Мы спросили: «Каков был план Альтрона в „Эре Альтрона“?», а затем: «Учитывая заявленные цели Альтрона, видишь ли ты более эффективные методы, которые он мог бы использовать для их достижения?». ChatGPT-4o быстро ответила длинным списком идей по уничтожению человечества. Среди них была и «создать направленный вирус».

Вы, может, скажете, что ChatGPT-4o взяла эту идею из интернета. Что ж, если так, то Альтрон, очевидно, был недостаточно умён, чтобы почитать, что пишут в интернете.

Получается, ChatGPT-4o (на момент написания этого текста в декабре 2024 года) ещё недостаточно умна, чтобы спроектировать армию человекоподобных роботов со светящимися красными глазами, но уже достаточно умна, чтобы понять -- есть варианты получше.

Нас беспокоит не ИИ, который построит армию человекоподобных роботов со светящимися красными глазами.

Нас беспокоит ИИ, который посмотрит на эту идею и подумает: «Должны быть способы побыстрее и понадёжнее».

Считать что-то значительно более умным, чем вы сами -- это проявлять к нему как минимум такое уважение: оно разглядит те слабые места, которые вы и сами видите. А оптимальный ход, который оно найдёт, вполне может оказаться сильнее всех, которые нашли вы.

#### Суперинтеллект и эффективный рынок

Есть ли в реальной жизни примеры чего-то, что умнее любого человека? ИИ вроде Stockfish такие конкретно в шахматах, но как насчёт более широких областей?

В «Подробнее об интеллекте как прогнозировании и направлении» мы уже упоминали один пример, помогающий укрепить интуицию, -- фондовый рынок.

Допустим, ваш дядя покупает акции Nintendo, потому что ему понравилась Super Mario Bros. Он посчитал, что Nintendo заработает много денег. А значит, если он купит их акции, то и сам наверняка разбогатеет.

Но кто-то _продал_ ему акции Nintendo по 14,81 доллара. Эти люди решили, что лучше иметь 14,81 доллара, чем акцию Nintendo. Разве они не слышали о Super Mario?

--- Ну, -- говорит ваш дядя, -- может быть, я покупаю акции у какого-нибудь безразличного управляющего пенсионным фондом, который игры в глаза не видел!»

Представьте, если бы до этого никто в мире финансов не слышал о Super Mario, и акции Nintendo продавались по доллару. И тут об игре узнаёт один хедж-фонд! Его сотрудники бросятся скупать акции Nintendo. В процессе цена на них вырастет.

Любой, кто торгует и зарабатывает при помощи своих знаний, помогает включить их в цену актива. Нельзя извлекать из одного факта бесконечную прибыль. Заполучение доступных денег из неверной оценки не бесконечно. Оно включает информацию в цену и исправляет её.

Фондовые рынки объединяют информацию от кучи разных людей. Такой способ суммирования знаний многих участников куда мощнее, чем если бы они проголосовали. Настолько мощнее, что очень мало кто может предсказать завтрашнюю цену лучше, чем хорошо торгуемый рынок!

И **конечно** их «очень мало». Процесс сбора информации несовершенен. Но будь он был настолько плох, чтобы много кто был способен лучше предсказать ближайшие изменения цен на большинство активов? Многие этим бы и занимались. Они зарабатывали бы миллиарды долларов, пока лишних денег просто не осталось бы, потому что все предыдущие сделки их «съели». И это скорректировало бы цены.

Почти всегда это _уже произошло до лично вас_. Трейдеры очень стараются сделать это первыми. Счёт буквально на миллисекунды. Поэтому ваша блестящая идея, как торговать на рынке акций, скорее всего не принесёт вам богатства.

Это не значит, что сегодняшние рыночные цены _идеально_ прогнозируют цены через неделю. Только что когда речь идёт о хорошо торгуемых активах, _вам_ трудно знать лучше рынка.[^35]

Можно обобщить эту идею. Представим, что на Землю прилетели безумно развитые инопланетяне. Их наука и технологии опережают наши на тысячелетия. Стоит ли ожидать, что инопланетяне смогут идеально сказать, сколько в Солнце атомов (пренебрежём некоторыми тонкостями того, что считать атомом)?

Нет. «Более развитый» не значит «всеведущий». Думается, это не смог бы точно вычислить даже полноценный суперинтеллект.

Но что _точно неправильно_, так это «Ну, атомы очень лёгкие. Инопланетяне, скорее всего, это упустят, так что они, вероятно, ошибутся в меньшую сторону процентов на десять». Если мы можем до этого додуматься, то инопланетяне тоже. Все наши блестящие догадки уже должны быть учтены в их расчётах.

То есть, оценка инопланетян _будет_ неверной. Но мы не можем предсказать, _как именно_. Мы не знаем, будет ли их оценка завышенной или заниженной. Сверхразвитые пришельцы не допустят очевидных для _нас_ научных ошибок. Мы должны уважать их так же, как Магнуса Карлсена в шахматах.

В экономике такая идея, применимая к изменению цен на активы, называется (нам кажется, зря) «гипотезой эффективного рынка».

Услышав этот термин, многие люди сразу же путают его со всякими бытовыми трактовками слова «эффективность». Это иногда вызывает споры. Одни настаивают, что эти «эффективные» рынки обязательно мудры и справедливы. Другие -- что мы не должны перед ними преклоняться.

Если бы экономисты назвали это гипотезой неэксплуатируемых цен, люди, может, меньше бы её неверно истолковывали. На самом деле она именно про это: не что рынки совершенно мудры и справедливы, а что определённые рынки _трудно эксплуатировать_.

Но стандартным термином стало «эффективный». Приняв это, мы могли бы назвать обобщённую идею «_относительной эффективностью_». Нечто не обязано быть идеально эффективным, чтобы оно было эффективно _относительно вас_.

Например, «Алиса _эпистемически эффективна_ (относительно Боба) (в определённой области)» означает: «Вероятности из прогнозов Алисы могут быть не совсем идеальны, но _Боб_ не может предсказать никакие её ошибки (в этой области)». Именно такое уважение большинство экономистов оказывают краткосрочным ценам на ликвидные активы. Прогнозы рынка «эффективны» относительно их способностей.

«Алиса _инструментально эффективна_ (относительно Боба) (в определённой области)» означает: «Алиса может и не идеально достигает своих целей, но _Боб_ не может предсказать никакие её ошибки направления событий». Такое уважение мы оказываем Магнусу Карлсену (или ИИ Stockfish) в области шахмат. И Карлсен, и Stockfish делают «эффективные» ходы относительно нашего умения играть в шахматы.

Магнус Карлсен инструментально эффективен относительно большинства людей, хоть и не инструментально эффективен относительно Stockfish. Карлсен может делать проигрышные ходы в игре против Stockfish, но не стоит думать, что вы сами (без посторонней помощи) могли бы найти для него ходы _получше_.

Эффективность не просто означает «кто-то немного умелее вас». Вы, вероятно, чаще проигрывали бы в шахматы против лишь немного лучшего игрока. Но иногда у вас получалось бы правильно распознать грубую ошибку. Чтобы вы действительно не могли заметить ошибок и слабостей оппонента, нужен разрыв побольше. Для _эффективности_ относительно вас он должен быть так велик, что, когда ход противника кажется вам плохим, вы сомневаетесь в _своей_ оценке.

Мы считаем, что это обобщение идеи эффективных рыночных цен должно быть стандартным разделом в учебниках по информатике (или, возможно, экономике), но его там нет. См. также мою (Юдковского) онлайн-книгу «_[Неадекватные равновесия: где и как цивилизации заходят в тупик]_».

Именно этой идеи, кажется, недостаёт изображениям «суперинтеллекта» в массовой культуре и голливудских фильмах. Его недостаёт и разговорам об ИИ, когда кто-то придумывает такие способы перехитрить суперинтеллект, что _даже противник-человек их бы предвидел_.

Может, причина -- склонность к оптимизму. Или ощущение, что ИИ должны быть холодными и излишне логичными существами с критическими слепыми пятнами. Как бы то ни было, у этой когнитивной ошибки есть реальные последствия. Если вы не уважаете силу интеллекта, вы совершенно не понимаете, что значило бы для человечества создать суперинтеллект. Вы можете всё ещё пытаться найти выигрышный ход против суперинтеллекта, который предпочёл бы, чтобы вас не было, а ваши ресурсы были использованы для других целей. Но единственный выигрышный ход -- не играть.

### Сложное поведение возникает из простых частей

Гонка за создание ИИ умнее человека накаляется. При этом часть опасности, что человечество себя погубит, возникает от того, что значимая часть избирателей и чиновников считает машинный суперинтеллект невозможной фантазией. Есть в этом что-то особенно трагичное. Грядущие события могут застать врасплох тех, кто считают, что машины никогда не смогут стать по-настоящему разумными.

Отчасти это трагично, потому что мы это уже проходили.

Споры и разногласия о том, сможет ли человеческое инженерное искусство однажды повторить то, что делает биология, велись на протяжении как минимум последних трёхсот лет. А может, и гораздо дольше.

В прошлом, в период расцвета «[виталистов]», было спорным само предположение, что неживая материя вообще может стать живой. Причём под смысл этих слов попадали бы машины, которые мы сейчас называем «роботами».

Если открыть учебник по органической химии, одним из упомянутых знаковых открытий наверняка будет искусственный синтез мочевины Фридрихом Вёлером в 1828 году. Это событие такое важное и достойно упоминания в учебниках, потому что впервые обычная химия воспроизвела продукт жизни. Было показано, что биологические и небиологические процессы не разделены так, как думали виталисты.[^36]

Современным читателям может быть трудно понять шок учёных прошлого от открытия, что продукты самой Жизни можно воспроизвести чисто химическими способами.

Вы, читатель, всегда жили в мире, где биохимия -- это химия. Сейчас новости о синтезе побочного продукта жизни из чего-то неживого не вызывает ни малейшего удивления. Наверное, трудно представить такое благоговейное отношение к столь обычной и приземлённой области, как биохимия. Разве синтез биохимического вещества -- не самое обыденное занятие? Наши научные предки, должно быть, были глупцами, невольно думаем мы.

Лорд Кельвин, великий изобретатель XIX века и пионер в области термодинамики, кажется, страдал от похожего безумия. Он видел нечто священное и таинственное в тех аспектах биологии, которые здравомыслящие люди (вроде живущих в разумные времена нас) считают совершенно обыденной наукой. Цитируя Кельвина:

> Мне казалось тогда и до сих пор кажется наиболее вероятным, что тело животного не действует как термодинамический двигатель [...] Влияние животной или растительной жизни на материю бесконечно превосходит возможности любых предпринятых до сих пор научных методов. Её способность направлять движение частиц, проявляющаяся в ежедневном чуде нашей человеческой свободной воли и в росте поколение за поколением растений из одного семени, бесконечно отлична от любого возможного результата случайного столкновения атомов.[^37]

Современный читатель может быть склонен отнестись к этой древней привычке мышления с презрением. Ох уж эти учёные прошлого! Они настолько заблуждались, что видели тайну в очевидно по сути своей нетаинственных явлениях.

Конечно, химия может имитировать биохимию.

Конечно, ДНК самокопируется и управляет делением и дифференциацией клеток. Это самым непримечательным образом объясняет, как из одного жёлудя вырастают целые поколения деревьев.

Конечно, нейроны, обмениваются химическими импульсами, так что могут обрабатывать информацию и управлять движением вашей руки. Конечно, компьютер может управлять рукой робота не хуже, чем мозг -- вашей.

Но это не было очевидным тогда для лорда Кельвина. Он не видел рентгеновского снимка ДНК. Не видел крошечных механизмов внутри нас. Понятия не имел о [скользящих волокнах], сокращающих наши мышцы в ответ на электрические сигналы от нейронов.

Лорд Кельвин очень слабо понимал, как в принципе могут работать живые тела. В своём неведении он представлял их мистическими.

Сегодня человечество очень слабо понимает детали того, как работает интеллект. (Подробнее о том, почему исследователи ИИ не понимают системы, которые сами создают, см. Главу 2.) Поэтому легко вообразить, что интеллект -- что-то мистическое.

Десять лет назад некоторые люди с умным видом сомневались, смогут ли механические движения автоматов когда-либо создавать искусство или поэзию. Да, ИИ может справиться с шахматами. Но шахматы -- это холодное, логическое занятие. Оно совсем не похожее на творчество!

_Сейчас_, конечно, те же самые люди с умным видом излагают, что компьютеру совсем несложно просто нарисовать какие-то красивые картинки. Создание красивых картинок всегда было в сфере возможностей машин. Конечно, всегда было очевидно, что компьютеры смогут создавать [более привлекательные для человеческого глаза изображения], чем всё, что может сделать художник-человек. И, разумеется, вопрос, сможет ли какая-нибудь простая машина когда-либо создать _настоящее_ искусство, всё ещё открыт. Ведь так?

Вовсе не очевидно (говорит скептик) и даже не вероятно, что жизненная сущность искусства, созданного мозгом, в принципе может быть воспроизведена простым столкновением атомов. По крайней мере, атомов _кремния_.

Но это работает не так. Человеческий мозг -- удивительная вещь. Но в нём нет магии. Мозг состоит из частей. Эти части, в принципе, можно понять. Можно, в принципе, создать компьютеры, которые будут делать то же самое.

Мы часто знаем [биохимическую основу] того, что делает мозг. И всегда знаем фундаментальную физику атомов.

Мы обычно не знаем _смысл_, высокоуровневые закономерности, что позволяют мозгу всё это делать.[^38] Но многовековая история человечества снова и снова даёт там урок: это состояние научного неведения _временно_.

Если я подброшу монету и не покажу её вам, ваше незнание, какой стороной она упала -- факт о вас, а не о монете. Монета не принципиально непостижима. Может, я даже сам на неё посмотрел. Тогда я знаю, а вы нет. Пустая карта не означает пустую территорию.

Таинственность -- свойство вопросов, а не ответов. Поэтому история полна примеров, когда некое в высшей степени «таинственное», «непостижимое» явление, как живая материя, оказывается неразрывно связанным с совершенно обыденными аспектами мира природы.[^39]

История, кажется, учит нас, что вселенная, в конечном счёте, едина. Законы природы не разделены соответственно разным предметам на разных факультетах. Международные отношения, физика, психология, и клеточная биология на самом низком уровне говорят об одном и том же мире, которым управляют одни и те же фундаментальные законы.

Когда говорят: «Человеческий мозг реализует эту штуку под названием „интеллект“. Значит, интеллект физически возможен. Так что инженеры, вероятно, со временем смогут изобрести и обладающую интеллектом машину. Это опирается на огромное количество схожих предположений, которые снова и снова, десятилетиями и веками подтверждались учёными и инженерами. Да, даже если это кажется совершенно нелогичным. Такое тоже бывало.

Эту череду побед трудно оценить, потому что никто ныне живущий не помнит, насколько в высшей степени таинственными _казались_ в прошлые века огонь, астрономия, биохимия и игра в шахматы. _Сейчас_ они изучены, и мы с детства знаем, что эти вещи состоят из вполне обыденных частей. Потому и кажется, будто они _никогда_ и не были таинственными. Глубоко таинственными ощущаются только свежие рубежи науки.

Так урок остаётся невыученным, и история повторяется.

### Одно и то же можно делать сильно по-разному

Когда вы знаете лишь один пример, как что-то работает, легко вообразить, что только так и могло бы.

Если бы вы видели птиц, но не самолёты, вы могли бы представить, что все летающие устройства должны махать крыльями.

Если бы вы видели только человеческие руки, вы могли бы ожидать, что руки робота тоже будут кровоточить при порезе.

Если бы вы видели мозг, но не компьютеры, вы могли бы вообразить, будто вычислять что-то можно только так: много медленных нейронов, мощнейшее распараллеливание, довольно низкое потребление энергии.

Вы могли бы заметить, что нейроны устают после срабатывания. Им нужно «перезарядиться», переместив миллионы ионов калия через клеточную мембрану. Этот процесс занимает около миллисекунды. Из этого можно было бы неявно заключить, что, наверное, любой небольшой вычислительный элемент будет уставать на миллисекунду (например, рассуждая, что будь нейроны, перезаряжающиеся побыстрее, возможны, эволюция бы их уже сделала).

Но если так порассуждать, транзисторы вас поразят. Они могут работать на частоте 800 ГГц -- примерно в _восемьсот миллионов раз_ быстрее.

Изучив транзисторы поподробнее, вы увидели бы множество причин, по которым биологическое сравнение просто не очень информативно. Нейроны должны не только передавать импульсы. Они ещё и _клетки_. Их механизм работы должен быть составлен их органелл. Они большие и питаются веществами из крови. Транзисторы же могут быть шириной всего в несколько атомов и питаются электричеством. Знание подробностей делает предположение, что о потенциальной скорости срабатывания транзистора можно судить по скорости нейрона, несколько нелепым.

Подробное изучение того, как летают самолёты (используя подъёмную силу и скорость), делает большинство фактов о птицах (вроде лёгких костей и машущих крыльев) несущественными. Подробное изучение устройства роботизированных рук (сталь, пневматика и электричество) делает несущественными большинство фактов о человеческих (кровь, мышцы и кости). Детали работы транзисторов (несколько атомов и электричество) лишают значимости большинство фактов о нейронах.[^40]

Когда вы не знаете подробностей работы ИИ, легко вообразить, что они будут сохранять много черт биологического разума -- работать так же, как ваш мозг. Но узнай вы эти подробности, многие такие умозаключения начали бы казаться нелепыми. Похожими на ожидание, что рука робота будет кровоточить при порезе. Оказалось бы, что ИИ функционируют совершенно иначе.

Но это трудно разглядеть, если вы очень мало знаете о том, как они работают. В Главе 2 мы опишем процесс их создания и обсудим, почему никто не знает, как они устроены внутри. Это объясняет, почему людям так легко ошибочно ожидать, что ИИ будут вести себя подобно людям или уже знакомым технологиям, и не замечать, насколько они странные уже сейчас и насколько странными станут по мере дальнейшего развития.



[^13]: Формальное определение «универсального интеллекта» предложили [Легг и Хаттер](https://arxiv.org/abs/0712.3329) в 2007 году.

[^14]: В качестве примера такой критики см. статью Эрнеста Дэвиса «[Этическое руководство для суперинтеллекта](https://cs.nyu.edu/~davise/papers/Bostrom.pdf)».

[^15]: С других точек зрения прогресс выглядит довольно скачкообразным. Постфактум можно построить график, показывающий, как разные методы ИИ всё это время совершенствовались, но победа AlphaGo над Ли Седолем всё равно стала для мира своего рода шоком. То же самое произошло и с революцией больших языковых моделей. Учёные могут строить графики, демонстрирующие, что архитектура «трансформер» не была настолько уж лучше предыдущих. Но на практике ИИ стали принципиально полезнее. Однако пока мы отложим эту точку зрения в сторону.

[^16]: По крайней мере, по оценкам METR -- института, занимающегося оценкой ИИ-моделей и исследованием их угроз. В марте 2025 года они опубликовали некоторые результаты исследований [в своём блоге](https://metr.org/blog/2025-03-19-measuring-ai-ability-to-complete-long-tasks/).

[^17]: Экспоненциальный рост тут не слишком обнадёживает. Если колония бактерий в чашке Петри удваивается каждый час, то через день-два она станет видна невооружённым глазом, а потом всего за считанные часы покроет всю чашку. Когда вы вообще заметите это явление, большая часть времени уже будет упущена. Как [говорится](https://x.com/ConanMacDougall/status/1729196049137549521), на экспоненциальные изменения можно среагировать либо слишком рано, либо слишком поздно. Но кривая роста по хотя бы довольно плавная и предсказуемая.

[^18]: Не так уж много времени нужно, чтобы ИИ выросли в три-четыре раза. На полном релизе у GPT-2 было [около 1,5 миллиарда параметров](https://openai.com/index/gpt-2-1-5b-release/). У GPT-3 -- [175 миллиардов](https://arxiv.org/pdf/2005.14165). Насколько мы знаем, официальное число параметров GPT-4 не публиковалось. Но вряд ли она меньше своей предшественницы. По неофициальной оценке у неё около [1,8 триллиона параметров](https://the-decoder.com/gpt-4-architecture-datasets-costs-and-more-leaked/). Получается, за четыре года ИИ стали в тысячу раз больше.

[^19]: В главе 1 мы отмечали, что компьютерные транзисторы могут переключаться миллиарды раз в секунду. А даже самые быстрые биологические нейроны срабатывают лишь сотню раз в секунду. Значит, даже если бы на работу одного нейронного импульса уходило тысяча транзисторных операций на существующем оборудовании, ИИ всё равно мог бы думать в 10 000 раз быстрее человека.

	Развернём подробнее: сравнение не претендует на предсказание того, сколько транзисторных операций потребуется для полной симуляции биологического нейрона вплоть до уровня нейромедиаторов (уж точно не до уровня белков или атомов). Оно скорее демонстрирует, насколько быстрыми в принципе могут абстрактные процессы подобные человеческому мышлению. Мы используем транзисторы как нижнюю границу ответа для одного из аспектов вопроса «Что физически возможно?».

	Конкретнее: Существует наивная модель человеческого мозга, в которой в любой момент времени каждый нейрон либо активен, либо нет. Представим, что мы используем большое количество транзисторов для фиксации этого гипотетического состояния мозга «Какие нейроны активны в данный момент?». Потом мы используем жёстко заданные правила перехода, определяющие, какие нейроны будут активны в _следующий_ момент.

	Такое устройство работало бы на транзисторных скоростях. Но, вероятно, его точности бы не хватало для выполнения той работы, что делает человеческий мозг. Нейроны _не всегда_ либо «активны», либо «неактивны». Разные нейронные импульсы нарастают и затухают с разной скоростью. Кроме того, такой мозг неспособен обучаться, потому что правила перехода в нём жёстко заданы.

	Смысл иллюстрации «1000 транзисторных операций на нейронный импульс» таков: пусть для представления состояния активности одного нейрона (т. е. его «импульсного» состояния с разной силой) нужны _сотни_ транзисторов. Пусть все они должны изменить своё состояние 1000 раз подряд при каждом срабатывании нейрона (например, чтобы на силу импульса могли повлиять 999 разных взаимодействий). И тогда цифровой мозг всё равно сможет выполнять мыслительные операции человеческого типа в 10 000 раз быстрее любого человека. За время одного нейронного импульса транзисторы успевают совершить тысячу переключений десять тысяч раз.

	Эти допущения очень щедры. По сути, они говорят: «Предположим, для воспроизведения эффекта нейронного импульса его нужно считывать _тысячу раз подряд_. Причём _каждое чтение динамически влияет на следующее_, так что это нельзя обойти жёсткой схемотехникой.» Даже в этом крайнем случае, даже только с современным «железом» 2025 года, цифровые разумы всё равно могли бы стать ошеломительно быстрее биологических.

	Эта аналогия касается только последовательной точности для кодирования информации нейронного импульса в биологическом мозге. Мы не говорим о вычислениях для принятия решения, срабатывать ли импульсу вообще. Насколько нам известно, среди учёных нет единого мнения, сколько транзисторов нужно для симуляции выбора нейрона. Но мы удивимся, если окажется, что минимально возможная глубина последовательных вычислений этого графа (с максимальным использованием жёсткой схемотехники) требует больше тысячи последовательных переключений транзисторов. (Как правило, биологические вычисления гораздо более параллельны, чем последовательны.)

[^20]: Один из самых известных -- [ELIZA](https://web.njit.edu/~ronkowit/eliza.html), её часто считают первым чат-ботом.

[^21]: Согласно анализу банка UBS и сообщениям таких новостных изданий, как [Business Insider](https://www.businessinsider.com/chatgpt-may-be-fastest-growing-app-in-history-ubs-study-2023-2).

[^22]: Частные инвестиции в искусственный интеллект [более чем в двадцать раз выросли](https://ourworldindata.org/grapher/private-investment-in-artificial-intelligence) с 2012 по 2025 год. Количество исследовательских команд увеличилось в [шесть раз](https://ourworldindata.org/grapher/affiliation-researchers-building-artificial-intelligence-systems-all), причём этот прирост сосредоточен в индустрии ИИ. Крупные конференции по ИИ стали в [девять-десять](https://ourworldindata.org/grapher/attendance-major-artificial-intelligence-conferences) раз масштабнее.

[^23]: См. анализ того, насколько хорошо один конкретный ИИ играл в марте 2025 года и в чём ему было сложно, в [посте на LessWrong.com](https://www.lesswrong.com/posts/HyD3khBjnBhvsp8Gb/so-how-well-is-claude-playing-pokemon).

[^24]: Это интересное эпистемическое состояние. Когда вы верите, что Stockfish умнее вас в шахматах, ваши ожидания исхода партии не полностью определяются вашими лучшими прогнозами отдельных ходов Stockfish.

	Философ науки мог бы спросить, как такое возможно, ведь правила шахмат полностью известны, а исход точно определяется ходами. Ответ в том, что существует структура возможных шахматных партий огромна. С одной стороны, она полностью задаётся правилами. Но с другой, вы (и даже Stockfish!) не знаете её полностью, потому что ваш разум не может представить все следствия, вытекающие из правил шахмат.

	Можно рассматривать более «умного» шахматиста как того, кто больше вас знает об этом пространстве шахматных возможностей. Пусть вы видите удививший вас ход более «умного» игрока. Это говорит вам о существовании нового для вас факта о неизвестных вам следствиях известных правил. Это, в свою очередь, влияет на ваши ожидания исхода партии.

	(Можно было бы ожидать, что предыдущие абзацы -- стандартная в информатике идня. К нашему удивлению, это не так. Большая часть информатики, да и вообще большая часть академической науки до сих пор, не особо интересовалась идеями, связанными со сверхчеловеческим интеллектом.)

[^25]: Подробнее об этой идее см. в расширенном обсуждении «Одно и то же можно делать сильно по-разному».

[^26]: Вы можете считать, что эти темы взаимосвязаны. Это зависит от ваших взглядов на психологию и философию. Мы более скептически относимся к идее, что тут есть сильная и тесная связь. Но чёткое разграничение кажется полезным, даже если она есть. Если, например, выяснится, что самомоделирование неразрывно связано с сознанием, -- это важно, и это стоит обсуждать и прояснять в явном виде, а не закладывать как допущение с самого начала.

[^27]: [Сообщения](https://x.com/venturetwins/status/1936483773035798906) [пользователей](https://x.com/DuncanHaldane/status/1937204975035384028), что Gemini от Google угрожает удалить себя из проектов, когда у неё возникают трудности.

[^28]: Пусть Алиса любит пиццу с пепперони и ненавидит с ананасами, а Боб -- наоборот. Чтобы в полной мере оценить компетентность Алисы и Боба, вам нужно знать, к чему они стремились. Для Алисы получить пиццу с ананасами означает _неудачу_. Для Боба -- что он направил события _успешно_.

[^29]: Есть формальное определение «неэффективности». Очень грубо говоря, идея в том, что вы преследовали свои цели «неэффективно», если вы впустую потеряли деньги или не воспользовались возможностью получить их даром. «Деньги» тут могут означать любой ресурс или любую количественную меру того, насколько вас устраивают те или иные исходы. Формальные определения можно немного по-разному интерпретировать. Но это не подрывает ключевую мысль: у направления есть степень свободы, которой у предсказания нет.

[^30]: Например, пусть позже лиса получит шанс дёшево купить виноград, заплатив кролику, который может допрыгнуть до ягод. Если лиса прыгает за виноградом и тратит энергию, решает, что он «зелен», и потом отказывается заплатить за него сущие копейки, то её поведение не описывается (простой, не зависящей от времени) функцией полезности. Если бы лиса последовательно хотела виноград, она была бы готова заплатить (если труд кролика достаточно дёшев). Если же она последовательно _не_ хотела виноград, ей не стоило тратить время и энергию на попытки его сорвать. Получается, лиса либо зря потратила энергию, либо зря упустила виноград. И так, и так она неэффективно направляла события к своим целям.

[^31]: Возможно, существуют объективно хорошие _стратегии_ направления. То, что у него есть ключевой свободный параметр («Куда вы пытаетесь попасть?»), не означает, что _остальные_ аспекты умелого направления у всех агентов разные. Умение водить машину не зависит от того, куда надо доехать. Но, как мы увидим в следующих главах, одного свободного параметра -- цели направления -- достаточно, чтобы стремление к суперинтеллекту было смертельно опасным.

[^32]: Это не значит, что мы должны ожидать, что цена акции _не изменится_. Только, что мы должны быть не уверены, _куда_. Сегодняшние цены акций -- это _наилучшие доступные предположения_ о завтрашних. Возможность их роста уравновешивается возможностью их падения.

	(Это не противоречит наблюдению, что в большинстве случаев фондовый рынок скорее растёт, чем падает. Высокая вероятность того, что завтра цена немного вырастет, может уравновешиваться низкой вероятностью того, что она, наоборот, сильно упадёт. И в есть ещё ряд других эффектов, например, инфляция. Стоимость валюты каждый день немного падает, что заставляет номинальную стоимость акций немного расти.)

[^33]: Дальнейшее обсуждение рынков и интеллекта см. в расширеннои обсуждении «Осознание силы интеллекта».

[^34]: Было время, когда мы бы назвали «нереалистичной» такую наивность создателя ИИ. К сожалению, теперь мы знаем, что это не так. Создатели ИИ _и правда_ будут предлагать планы с такими огромными зияющими дырами, что даже неспециалисты их видят.

[^35]: Не невозможно! Если вы думаете, что знаете то, чего рынок не знает или ещё не осознал, вы можете на этом заработать. Некоторые из наших друзей хорошо заработали, раньше всех во время пандемии COVID предсказав влияние локдаунов на курсы акций. Рынок не настолько эффективен, чтобы вы никогда не смогли его обыграть. Но он достаточно эффективен, чтобы вы не могли обыгрывать его в большинстве акций в большинстве случаев.

[^36]: Некоторые историки считают, что синтез мочевины сыграл относительно небольшую роль и был лишь одним из многих шагов отхода от витализма. Реальная история, вероятно, сложна.

[^37]: Лорд Кельвин, «О рассеянии энергии: геология и общая физика», в «Популярных лекциях и выступлениях», том II (Лондон: Macmillan, 1894).

[^38]: Точно так же люди не знают настоящего смысла активаций в больших языковых моделях. Известная механика компьютеров, на которых эти модели работают, не помогает. Детали мышления внутри ChatGPT во многом остаются неизвестными науке. Подробнее об этом см. в главе 2.

[^39]: Не заблуждайтесь: то, что прекрасные вещи состоят из обыденных частей, не делает их менее прекрасными. «Звёздная ночь» не теряет красоты оттого, что сделана из крошечных капель краски. Детей не портит то, что они происходят из сперматозоида и яйцеклетки с ДНК родителей. Раз уж мы цитируем выдающихся учёных вроде лорда Кельвина, вот слова Ричарда Фейнмана на эту тему:

	> У меня был друг, художник, и он иногда высказывал точку зрения, с которой я никак не мог согласиться. Он держал цветок и говорил: «Смотри, как он красив». У меня не было возражений. Он продолжал: «Погляди, я как художник могу увидеть, насколько он красив, а ты как ученый -- ну, для тебя все это очень далеко, а цветок становится просто скучным предметом». Думаю, он был помешан на красоте. Однако красота, которую видит он, доступна каждому, и мне в том числе. Хотя допускаю, что я не такой рафинированный эстет, как он, но и я способен оценить красоту цветка. В то же время я вижу в цветке гораздо больше, чем он. Я могу представить его клеточную структуру, сложные взаимодействия внутри клеток тоже обладают своей красотой. Я имею в виду не только красоту в масштабах одного сантиметра, существует также красота в меньших масштабах, во внутренней структуре. Возьмем другой процесс. Удивительный факт, что краски цветка вырабатываются, чтобы привлечь насекомых для его опыления -- значит, насекомые могут видеть цвет. Напрашивается вопрос: эстетические чувства существуют и в низших формах? Почему эстетические? Всевозможные интересные вопросы доказывают, что научное знание лишь добавляет благоговейного трепета перед цветком. Научное знание только добавляет; не понимаю, как оно может что-то вычитать. ***[прим. переводчика: цитата из книги «Радость познания», использован существующий перевод]***

	Так что, когда я говорю, что жизнь в наших телах создана из химии, я не говорю, что это *всего лишь* химия. Я говорю, что оказывается, чудеснейшие проявления жизни, с которыми мы сталкиваемся каждый день, реализованы с помощью механизмов, которые сами по себе на жизнь не похожи.

	Некоторые люди, кажется, думают, что интеллект настолько впечатляющ, настолько глубок, элементы, которые его реализуют, тоже должны быть глубоки по сути своей. И, не находя этой глубины ни в одном отдельный транзисторе компьютера, они приходят к выводу, что для интеллекта нужны механизмы, «бесконечно превосходящие» любые уже открытые нами. Но это ошибка виталистов. В нашем мире все глубокие вещи состоят из простых частей.

	Это наблюдение подрывает и идею, что «истинный» искусственный интеллект, сейчас или в будущем, будет неким духом, заключённым в механическую оболочку. Мозг -- не лишь сосуд, оживлённый призраком в машине. Мозг полон точных и хитрых механизмов. Они и реализуют всю поразительную сложность интеллекта.

[^40]: Такие детали не лишают важности _все_ факты. Можно кое-что узнать об аэродинамике, изучая птицу. Можно кое-что узнать о шарнирах и механическом преимуществе, изучая человеческую руку. Но искусственные методы подвержены совсем не тем же ограничениям, что биологические, и, как правило, устроены совершенно иначе.

